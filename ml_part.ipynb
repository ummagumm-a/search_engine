{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d60472d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0983a05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/medium.csv', nrows=1000)\n",
    "prep_df = pd.read_csv('data/prep_df.csv').applymap(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f54e3822",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommends</th>\n",
       "      <th>subTitle</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>A major private IT company implements blockcha...</td>\n",
       "      <td>Private Business, Government and Blockchain\\n\\...</td>\n",
       "      <td>Private Business, Government and Blockchain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>EPQ draft 1 (4844 words)\\nhttps://upload.wikim...</td>\n",
       "      <td>EPQ draft 1 (4844 words)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Various associations in the present days are o...</td>\n",
       "      <td>Ascent of data Science, SAS and Big data Analy...</td>\n",
       "      <td>Ascent of data Science, SAS and Big data Analy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recommends                                           subTitle  \\\n",
       "0           2  A major private IT company implements blockcha...   \n",
       "1           0                                       Introduction   \n",
       "2           0  Various associations in the present days are o...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Private Business, Government and Blockchain\\n\\...   \n",
       "1  EPQ draft 1 (4844 words)\\nhttps://upload.wikim...   \n",
       "2  Ascent of data Science, SAS and Big data Analy...   \n",
       "\n",
       "                                               title  \n",
       "0        Private Business, Government and Blockchain  \n",
       "1                           EPQ draft 1 (4844 words)  \n",
       "2  Ascent of data Science, SAS and Big data Analy...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24b5da6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subTitle</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>private business government blockchain</td>\n",
       "      <td>major private company implement blockchain art...</td>\n",
       "      <td>private business government blockchain major p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>epq draft word</td>\n",
       "      <td>introduction</td>\n",
       "      <td>epq draft word introduction automation set une...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ascent data science sa big data analyst traini...</td>\n",
       "      <td>various association present day open entryways...</td>\n",
       "      <td>ascent data science sa big data analyst traini...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0             private business government blockchain   \n",
       "1                                     epq draft word   \n",
       "2  ascent data science sa big data analyst traini...   \n",
       "\n",
       "                                            subTitle  \\\n",
       "0  major private company implement blockchain art...   \n",
       "1                                       introduction   \n",
       "2  various association present day open entryways...   \n",
       "\n",
       "                                                text  \n",
       "0  private business government blockchain major p...  \n",
       "1  epq draft word introduction automation set une...  \n",
       "2  ascent data science sa big data analyst traini...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60d97454",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy\n",
    "\n",
    "for_title = TfidfVectorizer(min_df=2)\n",
    "for_subTitle = TfidfVectorizer(min_df=3)\n",
    "for_text = TfidfVectorizer(min_df=5)\n",
    "\n",
    "tfidf_df = scipy.sparse.hstack([\n",
    "    for_title.fit_transform(prep_df['title']),\n",
    "    for_subTitle.fit_transform(prep_df['subTitle']),\n",
    "    for_text.fit_transform(prep_df['text']),\n",
    "]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05029c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "Path(\"models\").mkdir(exist_ok=True)\n",
    "\n",
    "def dump(model, in_str):\n",
    "    with open('models/' + in_str + '.pickle', 'wb') as handle:\n",
    "        pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "dump(for_title, 'for_title')\n",
    "dump(for_subTitle, 'for_subTitle')\n",
    "dump(for_text, 'for_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "287ca9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoders import text_to_vec\n",
    "\n",
    "def app_text_to_vec(X):\n",
    "    X = X.copy()\n",
    "    col_names = ['title', 'subTitle', 'text']\n",
    "    col_indexed = [[col + '_' + str(i) for i in range(300)] \n",
    "                   for col in col_names]\n",
    "\n",
    "    with mp.Pool(6) as pool:\n",
    "        dfs = []\n",
    "        for i in range(len(col_names)):\n",
    "            dfs.append(pd.DataFrame(\n",
    "                pool.map(text_to_vec, X[col_names[i]]), \n",
    "                index=X.index, \n",
    "                columns=col_indexed[i]\n",
    "            ))      \n",
    "       \n",
    "    return pd.concat(dfs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b73fcff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2v_df = app_text_to_vec(prep_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4315a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import save_npz\n",
    "save_npz('data/tfidf_df.npz', tfidf_df)\n",
    "w2v_df.to_csv('data/w2v_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55deb194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(tpl):\n",
    "    return list(map(lambda x: x.shape[1], tpl))\n",
    "\n",
    "def split_vec(vec, splits):\n",
    "    return (vec[:splits[0]],\n",
    "            vec[splits[0]:splits[0] + splits[1]],\n",
    "            vec[splits[0] + splits[1]:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "432f4305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from search import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c2d34c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones(10)\n",
    "b = np.zeros(10)\n",
    "b[:5] += 1\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5340807d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7071067811865475"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a421c2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11833, 11857, 63844]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_shape(tfidf_encode_query('machine learning'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e204018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = Document('machine learning', 'machine learning', 'machine learning', 5)\n",
    "score('machine learning', doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee82a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from search import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17f99227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  653,   903,  1049,  1078,  2837,  3163,  3194,  3565,  3881,\n",
       "        4660,  4885,  5047,  6399,  6672,  6818,  7325,  7359,  7431,\n",
       "        7614,  7635,  7776,  8494,  8773,  9022,  9345,  9814, 10915,\n",
       "       10952, 11870, 12153, 12181, 13048, 13724, 14494, 14867, 15894,\n",
       "       16396, 16599, 17346, 17621, 18627, 19592, 19961, 21403, 21433,\n",
       "       21877, 22350, 22379, 22428, 23142, 23240, 23538, 24484, 24863,\n",
       "       24987, 25113, 25321, 26335, 26805, 27160, 27199, 28617, 29018,\n",
       "       29326, 29370, 30193, 30289, 30423, 30458, 30541, 33175, 34101,\n",
       "       34224, 34333, 34451, 34685, 35455, 35947, 35980, 36117, 36158,\n",
       "       36348, 36393, 37299, 38113, 38224, 38398, 39087, 39112, 39147,\n",
       "       39333, 39364, 39789, 39968, 40633, 40912, 41670, 41714, 41858,\n",
       "       42323, 42645, 42654, 43686, 43719, 44231, 44299, 44865, 45275,\n",
       "       45803, 46049, 46248, 47485, 47491, 47676, 48332, 48887, 49167,\n",
       "       50273, 50285, 50293, 50568, 50893, 51267, 51872, 51954, 52162,\n",
       "       53001, 54935, 54992, 55336, 55563, 55604, 55847, 56248, 56712,\n",
       "       57073, 57076, 57733, 57756, 58683, 58886, 59043, 59225, 59480,\n",
       "       60078, 60232, 60931, 61407, 61495, 61849, 62317, 62341, 62497,\n",
       "       62796, 62943, 63094, 63286, 64615, 64829, 64886, 65327, 65694])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index._intersect_indices([\n",
    "    index.word_bank['facebook'],\n",
    "    index.word_bank['leak']\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc7b9715",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = index._intersect_indices([\n",
    "    index.word_bank['machine'],\n",
    "    index.word_bank['learning']\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2da7a1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 1161,  2472,  3024,  3309,  4712,  5974,  7238,  9596, 14985,\n",
       "            17177, 17686, 18083, 18470, 18553, 19788, 23336, 24251, 24575,\n",
       "            25205, 25269, 25639, 29133, 31381, 33448, 34195, 34465, 34543,\n",
       "            37454, 39891, 40945, 41329, 41584, 42645, 45934, 46451, 47654,\n",
       "            50560, 51285, 52048, 54566, 54655, 54844, 54960, 55152, 55257,\n",
       "            55466, 55526, 55735, 55822, 56053, 56835, 56985, 57050, 57168,\n",
       "            57186, 57852, 57896, 58013, 58252, 58385, 58533, 58913, 59097,\n",
       "            59237, 59426, 59640, 59703, 59837, 60056, 60291, 60337, 60671,\n",
       "            60754, 61222, 61402, 61434, 61463, 61524, 61756, 61978, 62039,\n",
       "            62741, 63051, 63355, 63402, 63493, 63746, 63988, 64225, 64264,\n",
       "            64589, 64749, 64911, 65090, 65118, 65445, 65566, 65794, 66041,\n",
       "            66129],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['recommends'][ind].sort_values(ascending=False).index[:100].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ebaccce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How Could Emotionally Intelligent Computers Change Our Society?\\nFig.1: Scene from Alex Garland’s ‘Ex Machina’\\nI used to think that humans would always have one advantage over AI. From this article’s title you can probably guess that I thought the advantage was our understanding of emotions. The conversations we have with our friends, the hours we spend analysing their meaning or the reading of subtle facial cues: surely, these would be the things that humans would always be able to do better than machines. As it turns out this is not quite right. In fact, the field of affective computing or emotion AI, which focuses on developing computers’ ability to read human emotions, has been quietly flourishing since 1997 when Rosalind Pricard published her seminal paper on the subject and established the Affective Computing Group at MIT Media Lab. In the more sophisticated terms of the Group itself:\\n‘Affective Computing is computing that relates to, arises from, or deliberately influences emotion or other affective phenomena.’\\nThe two decades since the paper was published were incredibly productive: both the technology and its applications have rapidly expanded, although not without their fair share of ethical grey areas. But first things first.\\nHow does it work and what are the use cases?\\nUsing tools as basic as a web cam, this software usually traces a person’s facial features by placing dots around their face, allowing it to read and analyse facial expressions down to minute details. The real strength of this is in machine learning, which allows the software to make an analysis based on enormous databases of facial expressions from around the world and often, account for differences in gender, nationality, cultural factors and more. Affectiva, a startup founded by Pricard and Rana el Kaliouby, for instance, has a database of 6.3 million unique facial expressions sourced from 87 countries. Altogether this data allows Affectiva to detect micro expressions that most would miss otherwise and make highly accurate predictions about people’s cognitive states at any given moment in time.\\nFig. 2: An example of Affectiva’s technology in action\\nUndoubtedly, this field came out of an excitement for possibilities of emotion analysis in healthcare. To give just one example: if before it was generally believed that children with autism would have abrupt and random meltdowns, the Affective Computing Group’s research and emotive analysis has shown that it is actually caused by a gradual increase in stress levels. Children experiencing sensory overload would often ‘shutdown’, making it look like they are feeling very calm. However, if the stress levels continue to rise this period of seeming relaxation can result in disruptive behaviour. Being able to accurately interpret emotions can help to rapidly prevent such outbursts by adjusting the external environment to suit the needs of the the child in advance. Other medical use cases involve utilising this software to better understand the state of mental health patients who might be struggling to communicate themselves, or for growing empathy in those who would have struggled to understand others’ emotions otherwise (e.g. patients with ASD, psychopaths). The potential of affective computing within healthcare seems vast and with good reason — it could help us understand those who have historically struggled to be heard, save lives and prevent unnecessary struggles for patients of all kinds.\\nHowever, use cases are not limited to healthcare. In business, such software can be applied to solve a broad spectrum of challenges: market research, sales prediction, recruiting, customer satisfaction analysis — you name it. Human, a similar emotion AI startup based in London has seen particular success with recruitment companies who want to eliminate human bias in the application process. In this scenario the recruiter sends videos of applicants to Human, who then analyse each one for particular traits. Do you want the most passionate candidate? Do you want the one with the most emotional intelligence? Whatever it is that you are looking for, Human can probably do it more objectively and accurately than your traditional interviewer.\\nFig.3: Human’s technology at work.\\nOne does not necessarily need to focus on face alone to make this analysis. Beyond Verbal claims that voice-based emotion analytics are one of the most important and relatively unexplored interfaces today. In some ways, they are probably right. My attempt to turn Alexa into a replica of Scarlet Johansson’s voice assistant in Her was unsuccessful, and I would say that her deadpan responses to my endless questions have played a significant part in that. Perhaps in a few years, someone who lives in isolation or is struggling through depression can not only ask to Alexa to tell them a funny joke, but actually ask for friendly advice that will feel genuine and will be based on complex understanding of the person’s emotional state at the time. Maybe advice is not even what the person is really after, maybe they just want someone to listen and the assistant will do just that. Again, the implications are far reaching. For many, it could be a personal aid, but companies will probably also take notice and use these assistants to gain unprecedented insights into their customers’ minds and offer more tailored customer service and relationship management in return. Whether this is creepy is another question, but it certainly seems it is within the realms of possible.\\nFig. 4: Scene from Spike Jonze’s ‘Her’\\nIt does not stop there. As if analysing facial micro-expressions and voice did not feel like digging deep enough, some are going even further. NuraLogix for instance, quite aptly noticed that the majority of our time our faces or voices do not show any emotions at all. What do you do then? You turn to a newly developed technique called transdermal optical imaging (TOI), which can see blood flow underneath your skin. The technology:\\n‘…uses face tracking technology to identify and track faces in a video stream. Blood flow data is then extracted using machine learning based bit-plane image analysis. Deep Learning based models are then applied to predict physiological and psychological affects.’\\nJudging from the website, the founders’ focus for the near future is on helping people to deal with stress and hypertension, but a quick patent search reveals that the company has already thought of using this tech for online market research and detecting deception for security purposes. As an example, instead of being awkwardly (and sometimes aggressively) patted down in airports after a luggage scan, a security officer could instead interview you with a camera to detect any unusual levels of anxiousness or even just leave it to the surveillance cameras to identify potential suspects. This would likely be both a less invasive and more efficient way of monitoring people in public places.\\nI will stop here with use cases because to list them all would be akin to trying to list every possible situation where emotions could make a difference, but if anyone wants more examples this and this contain a few more interesting ones.\\nWhat could go wrong?\\nTo me, this whole area is fascinating. On the one hand, people are inherently subjective, and therefore prone to making subconscious judgments and mistakes at virtually every opportunity. On the other, leaving it up to machines to understand human interactions seems equally discomforting. I somehow both love and hate this idea at the same time.\\nTake the recruiting example from above. It makes intuitive sense, and removing bias in the workplace is crucial in achieving fairness and establishing diversity, but my worry is that judging people’s potential by short snippets of their faces in a particular situation might not necessarily predict any one person’s performance in the long-term. If someone has learnt how to control their emotions better in preparation for an interview, should they necessarily rank higher than the person who did not? Does that say anything about how the person will perform on the job? Perhaps the tech is more advanced than I think and emotion AI’s analysis takes into account possible variations in context… but if it does not, then it seems we are under a big risk of training our software to make overgeneralised judgments that might not necessarily be representative of either the person or their potential. In the context of recruiting, or even beyond — how accurate can these short snippets of time be in our understanding of wider phenomena?\\nFig.5: Some image from 1984.\\nBut the thing that concerns me the most is the ethics, which just simply do not seem to be there yet. To describe just one situation where it could be morally dubious, Human is already working with an unspecified public authority to install its software in CCTV cameras to identify people who might be feeling suicidal. I can see why governments might think this works in favour of the public. They could be saving hundreds or even thousands of lives every year, but essentially this really starts resembling Orwell’s 1984. It diminishes personal freedoms and infringes on privacy, even if it is with the best intentions in mind. If a web cam is the only thing you need to use this tech, I can then easily imagine a resurrection of Google Glass-esque consumer products, which at best will make you paranoid and at worst, will make interacting with anyone using such wearables painful and impossible. The government will probably have to play an important regulatory role if affective computing will ever become freely available to consumers, but if many do not even agree with governmental ‘nudges’ to encourage healthier diets, I am not quite sure how the state will ever justify constant surveillance for people’s underlying emotional states. Will there be specific situations when their use will be allowed? Who will be allowed to use it? Should it even be left up to the government or any individual business to decide?\\nWhat if it the data gets into the wrong hands? What if someone hacks into a hospital’s database, steals information about vulnerable patients and exploits it to their own advantage? In job interviews, will people who show signs of depression be deemed less suitable for positions or have higher insurance premiums?\\nIn answer to “What could go wrong?” — a lot could go wrong. Affective computing has just as many possibilities as it has dangers and in order for us to not descend further into a dystopian world of mass surveillance and exploitation, I would encourage more of us to think about how to ensure that this technology will be used for the greater good.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[32770, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ab4a730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Cultural Revolution: Robots and Trust']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[title for title in df.title.tolist() if 'The Cultural Revolution: Robots and Trust' in title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23d36506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title.tolist().index('The Cultural Revolution: Robots and Trust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e8eefe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Cultural Revolution: Robots and Trust\\n\\nIt is important to understand where we are to see what the future holds. We live in a time of hedonism, what people call a hookup culture. Of disposable relationships. The most likely outcome is for the hookup culture to evolve. To a society is a similar situation Japan finds itself now. With the commodification of relationships. People will burn out, once this has run its course. Humans will have to connect based on connection and the want for children, as everything else has been parsed for profit or commodified.\\nThere are two things that have and will continue to hinder the hookup culture to this point, pregnancy and rape. While contraceptives have mitigated unwanted pregnancies, they are not fully effective. As to the latter subject, well, there likely isn’t a solution to that.\\nSo what happens when we add robots?\\nRobots and the Black Market\\nIt is important to tackle this issue as this will be one of the main reasons for the introduction of pleasure robots. Pandora’s box will likely be open because of this and it will also cause a major societal shift.\\nThe first major landmark ship shift will likely be pleasure robots.\\nThe sex trade a multi-billion dollar industry. It commodifies everything about human relationships. It is important to understand it exists because people want it and it is illegal. While the hookup culture has devalued the price for sex it has also made it easier for the black market to go undetected. The black market makes a profit off the sex trade by indentured servitude. Individuals are forced through debt, violence and addiction to continue hooking. Illegal operations have high costs both implicit and explicit.\\nRobots will be introduced to combat this illegal market. Robots offer many advantages they do not need food, water, sleep, and do not become pregnant. More importantly, they are not human, which means they can be considered property. Which, can be legally owned and mass produced. Mass production will cause the further commodification of sex. Which in-turn will likely drop its price to virtually zero as availability increases.\\nThis will force the illegal trade to do either compete on a comparable price point, try to compete on another level, or go out of business. Given the costs stated previously much of the market will dry up unless a caste system occurs. While there may be a higher end market it will be a small niche compared to the behemoth it is currently.\\nThus legalized robots will irrefutably damage the sex trade. However, the bigger consequence will be the commodification of sex.\\nFlipping Culture on its Head:\\nWidespread pleasure robots may kill the pornography industry if it does not evolve fast enough. While the industry has tried to adapt to the internet, few will continue to pay as the legalized widespread access of robots becomes available. The pornography industry will survive however if it adapts to Augmented and virtual reality, especially if sense integration occurs.\\nReligions, particular Christians will be torn on this issue. I mention Christians specifically because their religion is what Western society stands on, due to its values, laws, history etc. Is it adultery, if it isn’t human, let alone alive? Is a man or woman still chaste if only a robot has been involved? These and many other moral questions will need to be answered.\\nThe opening of Pandora’s box of robots, however, will eventually kill the hookup culture. As the prevalence of robots makes human interaction irrelevant. Men in particular who are disenfranchised by the current culture often drop out will now have an outlet. These individuals will be the first and will likely proselytize their lifestyle. Those who may respond with snark, I will remind that this is common in Japan. What starts as a taboo often becomes a societal norm.\\nThis will not be without its consequences. The more men who switch from traditional relationships to mechanical ones leaves more women without partners. While some may be filled by mechanical ones undoubtedly it will not be at the same pace. This due to women’s higher desire for connection than men, and men’s higher desire for sex. One of which is easily fulfilled, the other much harder. Thus a glut of women will likely compete for a smaller amount of men. With more options, men will become more selective. To compete for a mate a war of escalation will occur. This combined with technology needing for a culture of trust will increase the likelihood women will return to chastity until marriage.\\nThe legalization of these robots could, potentially prevent societal collapse and violence. As men and women who are unable to form social connections would now have an outlet for their unfulfilled needs. Individuals who have dropped out of society can now integrate to some degree. As the idea of pleasure robots becomes less stigmatized more people will begin to replace real relationships with robots. Robots will evolve to fulfill these new roles. Which will cause the further decline of relationships, marriage and birthrates.\\nChildren and Robots:\\nMale birth control methods are primitive at best. New innovations that reduce the downsides will increase the deliberate action to have children. Unplanned children will drop dramatically. This will also reduce potential “gold diggers”. Children will be a deliberate choice, by both parties.\\nThus birthrates will plummet. Far more then anyone can possibly imagine. People will call it the end of humanity, however, they lack vision. Artificial wombs may be the answer as humans can be created without the need for a female host. The other answer resembles a Margaret Atwood novel due to a crypto caste system.\\nArtificial wombs may also cause the idea of children to be more thought out, given the likelihood of genetic engineering. Children will be altered for optimum health. Mate selection in the future is quite likely to be based on genetics. Artificial wombs will likely lessen the maternal instinct of women and her potential child. Which will make the child more of a commodity than a unique being, due to less of a psychological attachment. Infanticide may increase due to this lack of connection.\\nMaternity, as we know of today, may be reserved for the rich. As the expense of rearing a child normally will be extremely high when compared to an artificial womb. It is entirely possible a system of sperm banks, genetic engineering and artificial wombs for adoptive parents emerges. One that selects for genetic diversity. This to reduce the likelihood of mass extinction while removing undesirable traits.\\nThe Outcome:\\nPersonal robots will be first reserved for the wealth due to the newness and complexity. So robots will operate in a manner similar to medieval brothels. Designated areas, cordoned off, especially if Artificial Intelligence continues to grow at the speed of Moore’s Law. Also due to the cost of ownership and maintenance. This will eventually move towards mass ownership as costs come down and the cultural stigma subsides. Crimes regarding adult prostitution and sexual violence will likely drop. Poverty may increase as prostitution becomes a less viable way to earn money.\\nThe culture will eventually accept albeit begrudgingly the robots as they move from pleasure to romantic companion. Women will likely choose chastity if the above situation occurs, even if they have the full cultural, legal and independent rights to do otherwise. But why? A war of escalation. While the majority may live their lives how they like, a small group will counter the rise of robots by doing the opposite of what the group does.\\nThis group will be more valued due to its rarity like all things, especially given the abundance of pleasure. This group will be hated however they will be more successful in obtaining relationships, all else equal. As a result, a cultural movement will emerge.\\nIn return, these women will want longer courtships as they only have one chance due to their choice. Men will agree, as pleasure is bountiful. Courtship will occur again, as the value of relationships takes on new meaning. A culture of trust. Similar to the Victorian era will develop. Courtship and chastity will be normal. Chaperones of robots or via the Internet of things is entirely possible. Trust and in turn honour will be valued. This due to the changing nature of relationships and the irreversibility of cryptographic transactions. Who you spend your time with, personally and in business, matter more.\\nThe irreversibility of cryptocurrency transactions will impact business. Marriage unions, the joining families to secure alliances and business ties may also occur once again. It sounds ridiculous now, but what is the likelihood you would rip off your family? I bet less likely than some random stranger. \\nLineage and Dynasty two words very uncommon today will likely make a resurgence into the public consciousness and lexicon.\\nConclusion:\\nIt is difficult to predict the full extent of how robots will change human society. This article offers a brief glimpse into what it may look like. Robots will likely speed up the current culture of hedonism, which will cause an eventual reversal. There will be three main robots that will change human society, pleasure robots, companion robots and artificial wombs.\\nOne thing is for certain they will be in every part of our lives, ubiquitous. It will often change unexpected things in ways we did not expect. It is possible men and women play more of an active role in courtship. With the ideas of connection and children being at the heart of a relationship. If so this would create more stable and longer lasting relationships.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[11, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1c468f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query: str):\n",
    "    # indices of documents with words from query\n",
    "    if query == '':\n",
    "        top = df.head(20)\n",
    "    else:\n",
    "        print(1)\n",
    "        indices = build_indices(query)\n",
    "        print(indices)\n",
    "\n",
    "        print(2)\n",
    "        query_tfidf, query_w2v = encode_query(query)\n",
    "        # take a subset of documents\n",
    "        print(2.5)\n",
    "        sub_df_tfidf = pd.DataFrame(tfidf_df[indices].toarray())\n",
    "        sub_df_w2v = w2v_df.iloc[indices, :]\n",
    "        print(3)\n",
    "        \n",
    "        # calculate similarities\n",
    "        sims = pd.Series(\n",
    "            0.3 * sub_df_tfidf.apply(lambda x: score_halved(query_tfidf, x), axis=1) \\\n",
    "            + 0.7 * sub_df_w2v.apply(lambda x: score_halved(query_w2v, x), axis=1),\n",
    "            index = indices)\n",
    "        print(4)\n",
    "    \n",
    "        top = sims.sort_values(ascending = False).head(20)\n",
    "        print('top:')\n",
    "        print(top.index)\n",
    "        print(5)\n",
    "\n",
    "    return df_to_docs(df.iloc[top.index, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd0036ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Int64Index([25639,  4712, 54844, 58913, 33448, 17686, 55257, 34195, 18470,\n",
      "            56835, 57896, 65445, 59097, 64589, 41329, 40945, 37454, 55735,\n",
      "            62741, 52048, 41584, 17177, 24575, 61222, 64749, 14985,  3309,\n",
      "            18083, 54655, 60671, 61756, 25205, 66129, 59703, 64264, 60337,\n",
      "            47654, 59237, 64911, 66041, 60056, 63402, 25269, 56985, 34465,\n",
      "            39891, 58533,  2472, 61524,  1161, 46451, 50560, 57168,  3024,\n",
      "            65090, 61402,  5974, 65794, 19788, 31381, 63051, 51285, 59837,\n",
      "            34543, 57050, 65566, 64225, 54960,  9596, 61463, 61434, 63746,\n",
      "            55822, 60754, 60291, 55526, 54566, 55466, 18553, 23336, 63355,\n",
      "            58013, 59426, 24251, 42645, 58252, 59640, 61978, 62039, 58385,\n",
      "            56053, 65118, 63493, 57852, 45934, 55152, 63988, 57186, 29133,\n",
      "             7238],\n",
      "           dtype='int64')\n",
      "2\n",
      "2.5\n",
      "3\n",
      "4\n",
      "top:\n",
      "Int64Index([25639,  4712, 54844, 58913, 33448, 17686, 55257, 34195, 18470,\n",
      "            56835, 57896, 65445, 59097, 64589, 41329, 40945, 37454, 55735,\n",
      "            62741, 52048],\n",
      "           dtype='int64')\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ummagumma/.local/lib/python3.10/site-packages/scipy/spatial/distance.py:699: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<document.Document at 0x7f2048776b00>,\n",
       " <document.Document at 0x7f200c7cc070>,\n",
       " <document.Document at 0x7f200c7cc0d0>,\n",
       " <document.Document at 0x7f200c7cc130>,\n",
       " <document.Document at 0x7f200c7cc190>,\n",
       " <document.Document at 0x7f200c7cc1f0>,\n",
       " <document.Document at 0x7f200c7cc250>,\n",
       " <document.Document at 0x7f200c7cc2b0>,\n",
       " <document.Document at 0x7f200c7cc310>,\n",
       " <document.Document at 0x7f200c7cc370>,\n",
       " <document.Document at 0x7f200c7cc3d0>,\n",
       " <document.Document at 0x7f200c7cc430>,\n",
       " <document.Document at 0x7f200c7cc490>,\n",
       " <document.Document at 0x7f200c7cc4f0>,\n",
       " <document.Document at 0x7f200c7cc550>,\n",
       " <document.Document at 0x7f200c7cc5b0>,\n",
       " <document.Document at 0x7f200c7cc610>,\n",
       " <document.Document at 0x7f200c7cc670>,\n",
       " <document.Document at 0x7f200c7cc6d0>,\n",
       " <document.Document at 0x7f200c7cc730>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve('machine learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1063739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
